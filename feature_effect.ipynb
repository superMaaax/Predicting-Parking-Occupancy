{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d64e678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "# =============================================================================\n",
    "# 0. Fixed Hyperparameters for Ablation\n",
    "# =============================================================================\n",
    "CSV_IN        = \"dataset.csv\"\n",
    "CSV_OUT       = \"ablation_results.csv\"\n",
    "\n",
    "LOOK_BACK     = 10\n",
    "WIN_SIZE      = 4\n",
    "OVERLAP       = 0.75\n",
    "WIN_STEP      = max(1, int(WIN_SIZE * (1 - OVERLAP)))\n",
    "N_WINDOWS     = (LOOK_BACK - WIN_SIZE) // WIN_STEP + 1\n",
    "INPUT_FEATURES_NUM = N_WINDOWS * 8 + 1  # 8 stats per window + effect\n",
    "\n",
    "HIDDEN_SIZE   = 8\n",
    "OUTPUT_FEATURES_NUM = 1\n",
    "NUM_LAYERS    = 1\n",
    "MAX_EPOCHS    = 1000\n",
    "LEARNING_RATE = 0.05\n",
    "CIRCLE        = 5\n",
    "\n",
    "# Prepare results file\n",
    "cols = [\"scenario\",\"LOOK_BACK\",\"WIN_SIZE\",\"OVERLAP\",\"WIN_STEP\",\"N_WINDOWS\",\"MSE\",\"RMSE\",\"RAE\",\"R2\"]\n",
    "pd.DataFrame(columns=cols).to_csv(CSV_OUT, index=False)\n",
    "\n",
    "# =============================================================================\n",
    "# 1. Data Import\n",
    "# =============================================================================\n",
    "def import_TSD_data(filename=CSV_IN):\n",
    "    df = pd.read_csv(filename)\n",
    "    trend  = df[\"rate\"].astype(\"float32\").values\n",
    "    cycle  = df[\"cycle\"].astype(\"float32\").values\n",
    "    effect = df[\"indicator_norm\"].astype(\"float32\").values\n",
    "    train_size = int(0.6 * len(trend))\n",
    "    return trend, cycle, effect, train_size\n",
    "\n",
    "trend_orig, cycle_orig, effect_orig, train_size = import_TSD_data()\n",
    "\n",
    "# =============================================================================\n",
    "# 2. Feature Builder (stats + effect), with separate target array\n",
    "# =============================================================================\n",
    "def build_stats_features(trend_feat, cycle, effect,\n",
    "                         look_back, win_size, win_step,\n",
    "                         trend_target=None):\n",
    "    target_offset = 2 * look_back\n",
    "    n_samples = len(trend_feat) - (look_back + target_offset)\n",
    "    X, y = [], []\n",
    "    for i in range(n_samples):\n",
    "        r_seg = trend_feat[i : i + look_back]\n",
    "        c_seg = cycle    [i : i + look_back]\n",
    "        feats = []\n",
    "        for w in range(0, look_back - win_size + 1, win_step):\n",
    "            r_win = r_seg[w : w + win_size]\n",
    "            c_win = c_seg[w : w + win_size]\n",
    "            feats.extend([\n",
    "                r_win.min(), r_win.max(), r_win.mean(), r_win.std(ddof=0),\n",
    "                c_win.min(), c_win.max(), c_win.mean(), c_win.std(ddof=0)\n",
    "            ])\n",
    "        feats.append(effect[i + target_offset])\n",
    "        X.append(feats)\n",
    "        # choose the target array: default to trend_feat if none passed\n",
    "        tgt = trend_target if trend_target is not None else trend_feat\n",
    "        y.append(tgt[i + target_offset])\n",
    "    return np.array(X, dtype=\"float32\"), np.array(y, dtype=\"float32\")\n",
    "\n",
    "# =============================================================================\n",
    "# 3. GRU Model Definition\n",
    "# =============================================================================\n",
    "class GRU_model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(input_size - 1, hidden_size, num_layers)\n",
    "        self.head = nn.Linear(hidden_size + 1, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (seq_len, batch, input_size)\n",
    "        seq, batch, _ = x.shape\n",
    "        data = x[:, :, :INPUT_FEATURES_NUM - 1]   # timeâ€‘series part\n",
    "        eff  = x[:, :, -1].unsqueeze(2)           # effect feature\n",
    "        out, _ = self.gru(data)                   # (seq_len, batch, hidden)\n",
    "        out = torch.cat([out, eff], dim=2).view(seq * batch, -1)\n",
    "        out = self.head(out)\n",
    "        return out.view(seq, batch, -1)\n",
    "\n",
    "# =============================================================================\n",
    "# 4. Train & Evaluate Function (accepts separate feature & target trends)\n",
    "# =============================================================================\n",
    "def TSD_GRU(trend_feat, cycle, effect, trend_target,\n",
    "            train_size, look_back, win_size, win_step):\n",
    "    # split feature vs target arrays\n",
    "    tr_feat, te_feat = trend_feat[:train_size], trend_feat[train_size:]\n",
    "    tr_tar,  te_tar  = trend_target[:train_size], trend_target[train_size:]\n",
    "    tr_cy,  te_cy   = cycle[:train_size],    cycle[train_size:]\n",
    "    tr_eff, te_eff  = effect[:train_size],   effect[train_size:]\n",
    "\n",
    "    # build stats features and correct targets\n",
    "    X_tr, y_tr = build_stats_features(tr_feat, tr_cy, tr_eff,\n",
    "                                      look_back, win_size, win_step,\n",
    "                                      trend_target=tr_tar)\n",
    "    X_te, y_te = build_stats_features(te_feat, te_cy, te_eff,\n",
    "                                      look_back, win_size, win_step,\n",
    "                                      trend_target=te_tar)\n",
    "\n",
    "    bs_tr, bs_te = X_tr.shape[0], X_te.shape[0]\n",
    "    feat_dim     = X_tr.shape[1]\n",
    "\n",
    "    # shape for GRU: (seq_len=1, batch, features)\n",
    "    X_tr_t = torch.from_numpy(X_tr).reshape(1, bs_tr, feat_dim)\n",
    "    y_tr_t = torch.from_numpy(y_tr).reshape(1, bs_tr, OUTPUT_FEATURES_NUM)\n",
    "    X_te_t = torch.from_numpy(X_te).reshape(1, bs_te, feat_dim)\n",
    "    y_te_t = torch.from_numpy(y_te).reshape(1, bs_te, OUTPUT_FEATURES_NUM)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = GRU_model(feat_dim, HIDDEN_SIZE,\n",
    "                      OUTPUT_FEATURES_NUM, NUM_LAYERS).to(device)\n",
    "    opt    = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    loss_fn= nn.MSELoss()\n",
    "\n",
    "    MSEs, RMSEs, RAEs, R2s = [], [], [], []\n",
    "\n",
    "    for _ in range(CIRCLE):\n",
    "        model.apply(lambda m: m.reset_parameters()\n",
    "                    if hasattr(m, \"reset_parameters\") else None)\n",
    "        # training\n",
    "        for _ in range(MAX_EPOCHS):\n",
    "            opt.zero_grad()\n",
    "            out = model(X_tr_t.to(device))\n",
    "            loss = loss_fn(out, y_tr_t.to(device))\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        # evaluation\n",
    "        with torch.no_grad():\n",
    "            pred = model(X_te_t.to(device)).cpu().view(-1).numpy()\n",
    "        actual = y_te_t.view(-1).numpy()\n",
    "        err = pred - actual\n",
    "\n",
    "        mse = (err**2).mean()\n",
    "        MSEs.append(mse)\n",
    "        RMSEs.append(np.sqrt(mse))\n",
    "        # safe RAE\n",
    "        denom = np.sum(np.abs(actual - actual.mean()))\n",
    "        rae   = np.sum(np.abs(err)) / denom if denom>0 else 0.0\n",
    "        RAEs.append(rae)\n",
    "        # safe R2\n",
    "        RSS = np.sum(err**2)\n",
    "        TSS = np.sum((actual - actual.mean())**2)\n",
    "        r2   = 1 - RSS/TSS if TSS>0 else 1.0\n",
    "        R2s.append(r2)\n",
    "\n",
    "    return np.mean(MSEs), np.mean(RMSEs), np.mean(RAEs), np.mean(R2s)\n",
    "\n",
    "# =============================================================================\n",
    "# 5. Ablation Scenarios & Loop\n",
    "# =============================================================================\n",
    "scenarios = {\n",
    "    \"all_features\": (trend_orig, cycle_orig, effect_orig),\n",
    "    \"no_trend\":     (np.zeros_like(trend_orig), cycle_orig, effect_orig),\n",
    "    \"no_cycle\":     (trend_orig, np.zeros_like(cycle_orig), effect_orig),\n",
    "    \"no_effect\":    (trend_orig, cycle_orig, np.zeros_like(effect_orig)),\n",
    "}\n",
    "\n",
    "for name, (t_feat, c_arr, e_arr) in scenarios.items():\n",
    "    mse, rmse, rae, r2 = TSD_GRU(\n",
    "        t_feat,       # trend for features\n",
    "        c_arr,\n",
    "        e_arr,\n",
    "        trend_orig,   # true trend for targets\n",
    "        train_size,\n",
    "        LOOK_BACK, WIN_SIZE, WIN_STEP\n",
    "    )\n",
    "    row = {\n",
    "        \"scenario\":  name,\n",
    "        \"LOOK_BACK\": LOOK_BACK,\n",
    "        \"WIN_SIZE\":  WIN_SIZE,\n",
    "        \"OVERLAP\":   OVERLAP,\n",
    "        \"WIN_STEP\":  WIN_STEP,\n",
    "        \"N_WINDOWS\": N_WINDOWS,\n",
    "        \"MSE\":       mse,\n",
    "        \"RMSE\":      rmse,\n",
    "        \"RAE\":       rae,\n",
    "        \"R2\":        r2\n",
    "    }\n",
    "    pd.DataFrame([row]).to_csv(CSV_OUT, mode='a', header=False, index=False)\n",
    "\n",
    "# 6. Print results\n",
    "print(pd.read_csv(CSV_OUT))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
